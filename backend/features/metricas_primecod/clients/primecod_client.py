"""
Cliente para integra√ß√£o com API PrimeCOD
Implementa√ß√£o segura de proxy backend para evitar exposi√ß√£o de token no frontend
"""

import requests
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from django.conf import settings
from django.core.cache import cache

logger = logging.getLogger(__name__)

class PrimeCODAPIError(Exception):
    """Exce√ß√£o personalizada para erros da API PrimeCOD"""
    pass

class PrimeCODClient:
    """Cliente para comunica√ß√£o segura com API PrimeCOD"""
    
    def __init__(self):
        self.base_url = "https://api.primecod.app/api"
        self.token = getattr(settings, 'PRIMECOD_API_TOKEN', None)
        
        if not self.token:
            raise PrimeCODAPIError("PRIMECOD_API_TOKEN n√£o configurado no settings")
        
        self.headers = {
            'Authorization': f'Bearer {self.token}',
            'Content-Type': 'application/json',
            'User-Agent': 'ChegouHub-Backend/1.0'
        }
        
        # Rate limiting OTIMIZADO
        self.last_request_time = 0
        self.min_request_interval = 0.2  # 200ms entre requests (OTIMIZADO de 500ms!)
        
        # Status mapping completo para portugu√™s (15 status PrimeCOD)
        self.status_mapping = {
            1: 'Pedido Realizado',      # Placed
            2: 'Embalado',              # Packed  
            3: 'Despachado',            # Dispatched
            4: 'Enviado',               # Shipped
            5: 'Chegada ao Destino',    # Chegada ao Destino (j√° em portugu√™s)
            6: 'Saiu para Entrega',     # Out for delivery
            7: 'Entregue',              # Delivered
            8: 'Recusado',              # Refused
            9: 'Retornando',            # Returning
            10: 'Devolvido',            # Returned
            11: 'Fora de Estoque',      # Out of stock
            12: 'Cancelado',            # Cancelled
            13: 'Erro',                 # Error
            15: 'Erro de Fulfillment',  # Fulfilment Error
            16: 'Incidente',            # Incident
            # Strings para compatibilidade (todos em portugu√™s)
            'Delivered': 'Entregue',
            'Canceled': 'Cancelado', 
            'Cancelled': 'Cancelado',
            'Confirmed': 'Pedido Realizado',
            'Pending': 'Pedido Realizado',
            'Shipped': 'Enviado',
            'Returned': 'Devolvido',
            'Placed': 'Pedido Realizado',
            'Packed': 'Embalado',
            'Dispatched': 'Despachado',
            'Out for delivery': 'Saiu para Entrega',
            'Refused': 'Recusado',
            'Returning': 'Retornando',
            'Out of stock': 'Fora de Estoque',
            'Error': 'Erro',
            'Fulfilment Error': 'Erro de Fulfillment',
            'Incident': 'Incidente',
        }
    
    def _rate_limit(self):
        """Implementa rate limiting b√°sico"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time
        
        if elapsed < self.min_request_interval:
            sleep_time = self.min_request_interval - elapsed
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
    
    def _make_request(self, method: str, url: str, **kwargs) -> requests.Response:
        """Faz requisi√ß√£o HTTP com tratamento de erros e rate limiting"""
        logger.error(f"üåê _make_request chamado: {method} {url}")
        logger.error(f"üåê Headers: {self.headers}")
        logger.error(f"üåê Kwargs: {kwargs}")
        
        self._rate_limit()
        logger.error(f"üåê Rate limit OK, fazendo requisi√ß√£o...")
        
        try:
            logger.error(f"üåê Fazendo requests.request...")
            response = requests.request(
                method=method,
                url=url,
                headers=self.headers,
                timeout=30,
                **kwargs
            )
            logger.error(f"üåê Response recebido: {response.status_code}")
            
            logger.info(f"PrimeCOD API {method} {url} - Status: {response.status_code}")
            
            if response.status_code == 401:
                raise PrimeCODAPIError("Token de autentica√ß√£o inv√°lido ou expirado")
            elif response.status_code == 429:
                raise PrimeCODAPIError("Rate limit excedido. Tente novamente em alguns minutos")
            elif response.status_code >= 400:
                raise PrimeCODAPIError(f"Erro da API PrimeCOD: {response.status_code} - {response.text}")
            
            return response
            
        except requests.RequestException as e:
            logger.error(f"üåê ‚ùå RequestException: {str(e)}")
            logger.error(f"üåê ‚ùå Erro na requisi√ß√£o para PrimeCOD: {str(e)}")
            raise PrimeCODAPIError(f"Erro de conectividade: {str(e)}")
        except Exception as e:
            logger.error(f"üåê ‚ùå Exception geral: {str(e)}")
            logger.error(f"üåê ‚ùå Tipo: {type(e)}")
            raise PrimeCODAPIError(f"Erro inesperado: {str(e)}")
    
    def get_orders(self, 
                   page: int = 1, 
                   date_range: Optional[Dict[str, str]] = None,
                   max_pages: int = 100,  # OTIMIZADO: Com 50 orders/p√°gina, 100 p√°ginas = 5000 orders
                   country_filter: Optional[str] = None) -> Dict:
        """
        Busca TODOS os orders da API PrimeCOD coletando todas as p√°ginas
        e aplicando filtros de data e pa√≠s localmente ap√≥s coleta completa.
        
        IMPLEMENTA√á√ÉO REVOLUCION√ÅRIA OTIMIZADA:
        - API PrimeCOD SUPORTA filtros nativos de data e status!
        - API suporta at√© 50 orders por p√°gina com payload correto
        - Filtros de pa√≠s ainda aplicados localmente (n√£o h√° par√¢metro nativo)
        - OTIMIZA√á√ÉO: 5x mais r√°pido (50 orders/p√°g vs 10) + filtros nativos!
        
        Args:
            page: P√°gina inicial (sempre 1 para coleta completa)
            date_range: {'start': 'YYYY-MM-DD', 'end': 'YYYY-MM-DD'} - aplicado NATIVAMENTE na API!
            max_pages: M√°ximo de p√°ginas para buscar (prote√ß√£o contra loop infinito)
            country_filter: Pa√≠s para filtrar localmente
            
        Returns:
            Dict com orders filtrados nativamente, total_pages OTIMIZADO, etc.
        """
        
        # Cache baseado apenas em coleta completa (sem filtros na API)
        cached_result = None
        cache_key = None
        try:
            import hashlib
            # Cache para coleta completa - n√£o inclui filtros pois s√£o aplicados localmente
            cache_data = "primecod_orders_complete_collection"
            cache_key = hashlib.md5(cache_data.encode()).hexdigest()[:20]
            cached_result = cache.get(cache_key)
            if cached_result:
                logger.info("üéØ Usando dados completos em cache, aplicando filtros localmente")
                # Aplicar filtros nos dados em cache
                all_orders = cached_result.get('all_orders_raw', [])
                filtered_orders = self._apply_local_filters(all_orders, date_range, country_filter)
                
                return {
                    'orders': filtered_orders,
                    'total_orders': len(filtered_orders),
                    'total_orders_raw': len(all_orders),
                    'pages_processed': cached_result.get('pages_processed', 0),
                    'total_pages': cached_result.get('total_pages', 0),
                    'date_range_applied': date_range,
                    'country_filter_applied': country_filter,
                    'status': 'success',
                    'data_source': 'cache'
                }
        except Exception as e:
            logger.warning(f"Cache n√£o dispon√≠vel, prosseguindo com coleta completa: {str(e)}")
            cached_result = None
        
        url = f"{self.base_url}/orders"
        
        # ‚ö° CORRE√á√ÉO CR√çTICA: Usar endpoint POST correto com payload JSON!
        # URL: https://api.primecod.app/api/orders (POST)
        # JSON payload com filtros e pagina√ß√£o
        payload = {
            "page": 1,  # Ser√° atualizado no loop
        }
        
        # Aplicar filtro de data no payload JSON se fornecido
        if date_range and date_range.get('start') and date_range.get('end'):
            # CORRE√á√ÉO CR√çTICA: Usar formato correto da API PrimeCod
            start_iso = f"{date_range['start']}T03:00:00.000Z"
            end_iso = f"{date_range['end']}T23:59:59.999Z"
            payload["creationDatesRange"] = {
                "startDate": start_iso,
                "endDate": end_iso
            }
            logger.info(f"üî• USANDO FILTROS CORRETOS de data no payload JSON: {start_iso} at√© {end_iso}")
            logger.info(f"‚ö° CORRE√á√ÉO APLICADA: creationDatesRange em vez de start_date/end_date")
        
        # RESULTADO ESPERADO: Payload JSON correto para API PrimeCOD!
        
        logger.info(f"üöÄ Iniciando coleta COMPLETA de orders PrimeCOD - OTIMIZADA!")
        logger.info(f"üöÄ URL base: {url}")
        logger.info(f"‚ö° JSON Payload: {payload}")
        logger.info(f"üî• CORRE√á√ÉO CR√çTICA: Usando endpoint POST com payload JSON!")
        logger.info(f"‚ö° CORRE√á√ÉO: Usando endpoint POST correto com payload JSON!")
        logger.info(f"‚ö° Performance 5x mais r√°pida: ~78 p√°ginas em vez de 388!")
        logger.info(f"üöÄ Filtros de data aplicados via payload JSON")
        
        all_orders = []
        current_page = 1  # SEMPRE come√ßar da p√°gina 1
        total_pages = None
        pages_processed = 0
        
        try:
            logger.info(f"üöÄ Iniciando loop para coletar at√© {max_pages} p√°ginas (prote√ß√£o contra timeout)...")
            
            # Monitoramento de progresso (SEM timeout preventivo)
            import time
            loop_start_time = time.time()
            
            while current_page <= max_pages:
                # Apenas monitorar progresso (SEM interromper por tempo)
                loop_duration = time.time() - loop_start_time
                
                logger.info(f"üìÑ Processando p√°gina {current_page} (tempo: {loop_duration:.1f}s)")
                
                # Prote√ß√£o contra loop infinito por n√∫mero de p√°ginas
                if pages_processed >= max_pages:
                    logger.warning(f"‚ö†Ô∏è Limite de {max_pages} p√°ginas atingido - interrompendo coleta")
                    break
                
                # ‚ö° CORRE√á√ÉO CR√çTICA: Usar POST com payload JSON
                payload["page"] = current_page
                logger.info(f"üåê Requisi√ß√£o POST: {url} com payload page={current_page}")
                
                response = self._make_request('POST', url, json=payload)
                logger.info(f"‚úÖ Response recebido - Status: {response.status_code}")
                
                data = response.json()
                logger.info(f"üìä Estrutura da resposta: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                
                # Extrair orders da resposta
                orders = data.get('data', [])
                logger.info(f"üì¶ Orders na p√°gina {current_page}: {len(orders)}")
                
                # CONDI√á√ÉO DE PARADA: p√°gina completamente vazia (0 orders)
                if not orders or len(orders) == 0:
                    logger.info(f"üèÅ P√°gina {current_page} completamente vazia (0 orders) - finalizando coleta")
                    break
                
                # PROTE√á√ÉO ADICIONAL: Se orders √© muito pequeno, pode indicar fim da coleta
                if len(orders) < 50:   # API POST retorna vari√°vel orders por p√°gina, menos orders indica fim ou √∫ltima p√°gina
                    logger.info(f"üîç P√°gina {current_page} com {len(orders)} orders - poss√≠vel fim da coleta (esperado: 50/p√°gina)")
                
                # Adicionar todos os orders desta p√°gina (SEM filtros)
                all_orders.extend(orders)
                
                # Obter informa√ß√µes de pagina√ß√£o da resposta
                if total_pages is None:
                    total_pages = data.get('last_page', current_page)
                    logger.info(f"üìä Total de p√°ginas detectado: {total_pages}")
                
                current_page += 1
                pages_processed += 1
                
                # Log de progresso REALISTA com tempo para detectar problemas
                if pages_processed % 10 == 0 or loop_duration > 20:  # Log a cada 10 p√°ginas ou se demorado
                    logger.info(f"üìä Progresso: {pages_processed} p√°ginas x 10 orders = {len(all_orders)} orders, tempo: {loop_duration:.1f}s")
                
                # Log mais frequente quando pr√≥ximo do total esperado
                if (total_pages and current_page > total_pages - 5):
                    logger.info(f"üîç Status: p√°gina {current_page}/{total_pages or '?'}, orders desta p√°gina: {len(orders)}, tempo: {loop_duration:.1f}s")
            
            # An√°lise do motivo da parada
            final_duration = time.time() - loop_start_time
            
            logger.info(f"üéØ Coleta OTIMIZADA finalizada:")
            logger.info(f"‚è±Ô∏è Dura√ß√£o total: {final_duration:.1f} segundos")
            logger.info(f"‚ö° RESULTADO: {pages_processed} p√°ginas x ~50 orders = {len(all_orders)} orders coletados!")
            logger.info(f"üìä M√©dia REAL de orders/p√°gina: {len(all_orders)/pages_processed if pages_processed > 0 else 0:.1f}")
            logger.info(f"üìÑ √öltima p√°gina processada: {current_page - 1}")
            logger.info(f"üìä Total de p√°ginas dispon√≠veis detectado: {total_pages}")
            logger.info(f"üî• CORRE√á√ÉO APLICADA: Endpoint POST correto com payload JSON!")
            
            if pages_processed >= max_pages:
                logger.warning(f"‚ö†Ô∏è Coleta interrompida: atingiu limite m√°ximo de {max_pages} p√°ginas")
                logger.warning(f"‚ö†Ô∏è Se voc√™ esperava mais dados, aumente o par√¢metro max_pages ou remova o limite")
            else:
                logger.info(f"‚úÖ Coleta finalizada normalmente: encontrou p√°gina vazia na p√°gina {current_page}")
            
            # Salvar dados completos no cache ANTES de aplicar filtros
            if cache_key:
                try:
                    cache_data = {
                        'all_orders_raw': all_orders,
                        'pages_processed': pages_processed,
                        'total_pages': total_pages,
                        'collected_at': datetime.now().isoformat()
                    }
                    cache.set(cache_key, cache_data, 600)  # Cache por 10 minutos
                    logger.info(f"üíæ Dados completos salvos no cache")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Falha ao salvar no cache: {str(e)}")
            
            # ‚ö° FILTROS: Data via payload JSON, pa√≠s localmente
            logger.info(f"üîç Aplicando filtro de PA√çS localmente aos {len(all_orders)} orders (data via payload JSON)")
            # Se data foi aplicada via payload JSON, n√£o aplicar novamente localmente
            date_range_local = None if (date_range and date_range.get('start') and date_range.get('end')) else date_range
            filtered_orders = self._apply_local_filters(all_orders, date_range_local, country_filter)
            
            result = {
                'orders': filtered_orders,
                'total_orders': len(filtered_orders),
                'total_orders_raw': len(all_orders),
                'pages_processed': pages_processed,
                'total_pages': total_pages,
                'date_range_applied': date_range,
                'country_filter_applied': country_filter,
                'status': 'success',
                'data_source': 'api_optimized',
                'filtros_payload_json_aplicados': bool(date_range and date_range.get('start') and date_range.get('end'))
            }
            
            logger.info(f"‚úÖ Busca OTIMIZADA finalizada com sucesso:")
            logger.info(f"üì¶ Orders coletados (bruto): {len(all_orders)}")
            logger.info(f"üîç Orders ap√≥s filtros aplicados: {len(filtered_orders)}")
            logger.info(f"üìÑ P√°ginas processadas: {pages_processed}")
            logger.info(f"üî• Filtro de data aplicado via PAYLOAD JSON: {'Sim' if date_range and date_range.get('start') else 'N√£o'}")
            logger.info(f"üåç Filtro de pa√≠s aplicado localmente: {'N√£o (Todos os pa√≠ses)' if not country_filter or country_filter.lower().strip() in ['todos', 'todos os pa√≠ses', 'all', 'all countries'] else f'Sim ({country_filter})'}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar orders PrimeCOD: {str(e)}")
            raise PrimeCODAPIError(f"Erro na busca de orders: {str(e)}")
    
    def get_orders_with_progress(self, 
                                page: int = 1, 
                                date_range: Optional[Dict[str, str]] = None,
                                max_pages: int = 100,
                                country_filter: Optional[str] = None,
                                progress_callback: Optional[callable] = None) -> Dict:
        """
        Vers√£o de get_orders com callback de progresso para jobs ass√≠ncronos
        
        Args:
            page: P√°gina inicial (sempre 1 para coleta completa)
            date_range: {'start': 'YYYY-MM-DD', 'end': 'YYYY-MM-DD'} - aplicado NATIVAMENTE na API!
            max_pages: M√°ximo de p√°ginas para buscar
            country_filter: Pa√≠s para filtrar localmente
            progress_callback: Fun√ß√£o chamada a cada p√°gina: callback(pages_processed, orders_collected, elapsed_time, total_pages)
            
        Returns:
            Dict com orders filtrados nativamente, total_pages OTIMIZADO, etc.
        """
        
        # Cache baseado apenas em coleta completa (sem filtros na API)
        cached_result = None
        cache_key = None
        try:
            import hashlib
            # Cache para coleta completa - n√£o inclui filtros pois s√£o aplicados localmente
            cache_data = "primecod_orders_complete_collection"
            cache_key = hashlib.md5(cache_data.encode()).hexdigest()[:20]
            cached_result = cache.get(cache_key)
            if cached_result:
                logger.info("üéØ Usando dados completos em cache, aplicando filtros localmente")
                # Aplicar filtros nos dados em cache
                all_orders = cached_result.get('all_orders_raw', [])
                filtered_orders = self._apply_local_filters(all_orders, date_range, country_filter)
                
                return {
                    'orders': filtered_orders,
                    'total_orders': len(filtered_orders),
                    'total_orders_raw': len(all_orders),
                    'pages_processed': cached_result.get('pages_processed', 0),
                    'total_pages': cached_result.get('total_pages', 0),
                    'date_range_applied': date_range,
                    'country_filter_applied': country_filter,
                    'status': 'success',
                    'data_source': 'cache'
                }
        except Exception as e:
            logger.warning(f"Cache n√£o dispon√≠vel, prosseguindo com coleta completa: {str(e)}")
            cached_result = None
        
        url = f"{self.base_url}/orders"
        
        # ‚ö° CORRE√á√ÉO CR√çTICA: Usar endpoint POST correto com payload JSON!
        # URL: https://api.primecod.app/api/orders (POST)
        # JSON payload com filtros e pagina√ß√£o  
        payload = {
            "page": 1,  # Ser√° atualizado no loop
        }
        
        # Aplicar filtro de data no payload JSON se fornecido
        if date_range and date_range.get('start') and date_range.get('end'):
            # CORRE√á√ÉO CR√çTICA: Usar formato correto da API PrimeCod
            start_iso = f"{date_range['start']}T03:00:00.000Z"
            end_iso = f"{date_range['end']}T23:59:59.999Z"
            payload["creationDatesRange"] = {
                "startDate": start_iso,
                "endDate": end_iso
            }
            logger.info(f"üî• USANDO FILTROS CORRETOS de data no payload JSON: {start_iso} at√© {end_iso}")
            logger.info(f"‚ö° CORRE√á√ÉO APLICADA: creationDatesRange em vez de start_date/end_date")
        
        # RESULTADO ESPERADO: Payload JSON correto para API PrimeCOD!
        
        logger.info(f"üöÄ Iniciando coleta ASS√çNCRONA de orders PrimeCOD!")
        logger.info(f"üöÄ URL base: {url}")
        logger.info(f"‚ö° JSON Payload: {payload}")
        logger.info(f"üî• CORRE√á√ÉO ASS√çNCRONA: Usando endpoint POST com payload JSON!")
        logger.info(f"‚ö° CORRE√á√ÉO: Usando payload JSON correto para API PrimeCOD!")
        logger.info(f"üöÄ Filtros de data via payload JSON, pa√≠s localmente")
        
        all_orders = []
        current_page = 1  # SEMPRE come√ßar da p√°gina 1
        total_pages = None
        pages_processed = 0
        
        try:
            logger.info(f"üöÄ Iniciando loop ASS√çNCRONO para coletar at√© {max_pages} p√°ginas...")
            
            # Monitoramento de progresso para jobs ass√≠ncronos
            import time
            loop_start_time = time.time()
            
            while current_page <= max_pages:
                loop_duration = time.time() - loop_start_time
                
                logger.info(f"üìÑ Processando p√°gina {current_page} (tempo: {loop_duration:.1f}s)")
                
                # Prote√ß√£o contra loop infinito por n√∫mero de p√°ginas
                if pages_processed >= max_pages:
                    logger.warning(f"‚ö†Ô∏è Limite de {max_pages} p√°ginas atingido - interrompendo coleta")
                    break
                
                # ‚ö° CORRE√á√ÉO CR√çTICA: Usar POST com payload JSON
                payload["page"] = current_page
                logger.info(f"üåê Requisi√ß√£o ASS√çNCRONA POST: {url} com payload page={current_page}")
                
                response = self._make_request('POST', url, json=payload)
                logger.info(f"‚úÖ Response recebido - Status: {response.status_code}")
                
                data = response.json()
                
                # Extrair orders da resposta
                orders = data.get('data', [])
                logger.info(f"üì¶ Orders na p√°gina {current_page}: {len(orders)}")
                
                # CONDI√á√ÉO DE PARADA: p√°gina completamente vazia (0 orders)
                if not orders or len(orders) == 0:
                    logger.info(f"üèÅ P√°gina {current_page} completamente vazia (0 orders) - finalizando coleta")
                    break
                
                # PROTE√á√ÉO ADICIONAL: Se orders √© muito pequeno, pode indicar fim da coleta
                if len(orders) < 50:   # API POST retorna vari√°vel orders por p√°gina, menos orders indica fim ou √∫ltima p√°gina
                    logger.info(f"üîç P√°gina {current_page} com {len(orders)} orders - poss√≠vel fim da coleta (esperado: 50/p√°gina)")
                
                # Adicionar todos os orders desta p√°gina (SEM filtros)
                all_orders.extend(orders)
                
                # Obter informa√ß√µes de pagina√ß√£o da resposta
                if total_pages is None:
                    total_pages = data.get('last_page', current_page)
                    logger.info(f"üìä Total de p√°ginas detectado: {total_pages}")
                
                current_page += 1
                pages_processed += 1
                
                # Callback de progresso para jobs ass√≠ncronos
                if progress_callback:
                    try:
                        progress_callback(pages_processed, len(all_orders), loop_duration, total_pages)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erro no callback de progresso: {str(e)}")
                
                # Log de progresso a cada 10 p√°ginas
                if pages_processed % 10 == 0:
                    logger.info(f"üìä Progresso ASS√çNCRONO: {pages_processed} p√°ginas x ~50 orders = {len(all_orders)} orders, tempo: {loop_duration:.1f}s")
            
            # An√°lise do motivo da parada
            final_duration = time.time() - loop_start_time
            
            logger.info(f"üéØ Coleta ASS√çNCRONA finalizada:")
            logger.info(f"‚è±Ô∏è Dura√ß√£o total: {final_duration:.1f} segundos ({final_duration/60:.1f} min)")
            logger.info(f"‚ö° RESULTADO: {pages_processed} p√°ginas x ~50 orders = {len(all_orders)} orders coletados!")
            logger.info(f"üìä M√©dia REAL de orders/p√°gina: {len(all_orders)/pages_processed if pages_processed > 0 else 0:.1f}")
            logger.info(f"üìÑ √öltima p√°gina processada: {current_page - 1}")
            logger.info(f"üìä Total de p√°ginas dispon√≠veis detectado: {total_pages}")
            
            if pages_processed >= max_pages:
                logger.warning(f"‚ö†Ô∏è Coleta interrompida: atingiu limite m√°ximo de {max_pages} p√°ginas")
                logger.warning(f"‚ö†Ô∏è Para coletar mais dados, aumente o par√¢metro max_pages")
            else:
                logger.info(f"‚úÖ Coleta finalizada normalmente: encontrou p√°gina vazia na p√°gina {current_page}")
            
            # Salvar dados completos no cache ANTES de aplicar filtros
            if cache_key:
                try:
                    cache_data = {
                        'all_orders_raw': all_orders,
                        'pages_processed': pages_processed,
                        'total_pages': total_pages,
                        'collected_at': datetime.now().isoformat()
                    }
                    cache.set(cache_key, cache_data, 600)  # Cache por 10 minutos
                    logger.info(f"üíæ Dados completos salvos no cache")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Falha ao salvar no cache: {str(e)}")
            
            # ‚ö° FILTROS ASS√çNCRONOS: Data via payload JSON, pa√≠s localmente
            logger.info(f"üîç Aplicando filtro de PA√çS localmente aos {len(all_orders)} orders ASS√çNCRONOS (data via payload JSON)")
            # Se data foi aplicada via payload JSON, n√£o aplicar novamente localmente
            date_range_local = None if (date_range and date_range.get('start') and date_range.get('end')) else date_range
            filtered_orders = self._apply_local_filters(all_orders, date_range_local, country_filter)
            
            result = {
                'orders': filtered_orders,
                'total_orders': len(filtered_orders),
                'total_orders_raw': len(all_orders),
                'pages_processed': pages_processed,
                'total_pages': total_pages,
                'date_range_applied': date_range,
                'country_filter_applied': country_filter,
                'status': 'success',
                'data_source': 'async_api_optimized',
                'filtros_payload_json_aplicados': bool(date_range and date_range.get('start') and date_range.get('end'))
            }
            
            logger.info(f"‚úÖ Busca ASS√çNCRONA OTIMIZADA finalizada com sucesso:")
            logger.info(f"üì¶ Orders coletados (bruto): {len(all_orders)}")
            logger.info(f"üîç Orders ap√≥s filtros aplicados: {len(filtered_orders)}")
            logger.info(f"üìÑ P√°ginas processadas: {pages_processed}")
            logger.info(f"üî• Filtro de data aplicado via PAYLOAD JSON: {'Sim' if date_range and date_range.get('start') else 'N√£o'}")
            logger.info(f"üåç Filtro de pa√≠s aplicado localmente: {'N√£o (Todos os pa√≠ses)' if not country_filter or country_filter.lower().strip() in ['todos', 'todos os pa√≠ses', 'all', 'all countries'] else f'Sim ({country_filter})'}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar orders PrimeCOD ASS√çNCRONO: {str(e)}")
            raise PrimeCODAPIError(f"Erro na busca ass√≠ncrona de orders: {str(e)}")
    
    def _apply_local_filters(self, orders: List[Dict], date_range: Optional[Dict[str, str]] = None, country_filter: Optional[str] = None) -> List[Dict]:
        """
        Aplica todos os filtros localmente aos orders coletados
        
        Args:
            orders: Lista completa de orders da API
            date_range: Filtro de data {'start': 'YYYY-MM-DD', 'end': 'YYYY-MM-DD'}
            country_filter: Nome do pa√≠s para filtrar
            
        Returns:
            Lista de orders filtrados
        """
        if not orders:
            logger.info("üîç Nenhum order para filtrar")
            return orders
        
        filtered_orders = orders.copy()
        logger.info(f"üîç Iniciando filtros locais: {len(filtered_orders)} orders")
        
        # Aplicar filtro de data se especificado
        if date_range and date_range.get('start') and date_range.get('end'):
            logger.info(f"üìÖ Aplicando filtro de data: {date_range['start']} at√© {date_range['end']}")
            filtered_orders = self._filter_orders_by_date(filtered_orders, date_range)
            logger.info(f"üìÖ Ap√≥s filtro de data: {len(filtered_orders)} orders")
        
        # Aplicar filtro de pa√≠s se especificado E se n√£o for "todos"
        if country_filter and country_filter.lower().strip() not in ['todos', 'todos os pa√≠ses', 'all', 'all countries']:
            logger.info(f"üåç Aplicando filtro de pa√≠s: {country_filter}")
            filtered_orders = self._filter_orders_by_country(filtered_orders, country_filter)
            logger.info(f"üåç Ap√≥s filtro de pa√≠s: {len(filtered_orders)} orders")
        elif country_filter:
            logger.info(f"üåç Filtro de pa√≠s '{country_filter}' detectado como 'TODOS' - pulando filtro de pa√≠s")
        
        logger.info(f"‚úÖ Filtros aplicados: {len(orders)} -> {len(filtered_orders)} orders")
        return filtered_orders
    
    def _filter_orders_by_date(self, orders: List[Dict], date_range: Dict[str, str]) -> List[Dict]:
        """Filtra orders por data localmente"""
        logger.info(f"üìÖ Aplicando filtro de data: {date_range}")
        
        if not date_range.get('start') or not date_range.get('end'):
            logger.info("üìÖ Filtro de data incompleto, retornando todos os orders")
            return orders
        
        try:
            start_date = datetime.strptime(date_range['start'], '%Y-%m-%d').date()
            end_date = datetime.strptime(date_range['end'], '%Y-%m-%d').date()
            
            logger.info(f"üìÖ Per√≠odo de filtro: {start_date} at√© {end_date}")
            
            filtered_orders = []
            orders_without_date = 0
            
            for order in orders:
                # Tentar diferentes campos de data
                order_date_str = order.get('created_at') or order.get('date') or order.get('order_date')
                
                if not order_date_str:
                    orders_without_date += 1
                    continue
                
                try:
                    # Tentar diferentes formatos de data
                    order_date = None
                    # Extrair apenas a parte da data (primeiros 10 caracteres)
                    date_part = str(order_date_str)[:10]
                    
                    for date_format in ['%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y']:
                        try:
                            order_date = datetime.strptime(date_part, date_format).date()
                            break
                        except ValueError:
                            continue
                    
                    if not order_date:
                        orders_without_date += 1
                        continue
                    
                    # Verificar se a data est√° no per√≠odo especificado
                    if start_date <= order_date <= end_date:
                        filtered_orders.append(order)
                        
                except (ValueError, TypeError) as e:
                    orders_without_date += 1
                    continue
            
            logger.info(f"üìÖ Resultado do filtro de data:")
            logger.info(f"   - Orders no per√≠odo: {len(filtered_orders)}")
            logger.info(f"   - Orders sem data v√°lida: {orders_without_date}")
            logger.info(f"   - Total processados: {len(orders)}")
            
            return filtered_orders
            
        except ValueError as e:
            logger.error(f"‚ùå Erro no filtro de data: {str(e)}")
            return orders
    
    def _filter_orders_by_country(self, orders: List[Dict], country_filter: str) -> List[Dict]:
        """Filtra orders por pa√≠s localmente"""
        logger.info(f"üåç Aplicando filtro de pa√≠s: {country_filter}")
        
        if not country_filter:
            logger.info(f"üåç Country filter vazio - retornando todos os orders")
            return orders
        
        # Se o filtro for "todos" em qualquer varia√ß√£o, retornar todos
        if country_filter.lower().strip() in ['todos', 'todos os pa√≠ses', 'all', 'all countries']:
            logger.info(f"üåç Country filter '{country_filter}' detectado como 'TODOS' - retornando todos os orders")
            return orders
        
        filtered_orders = []
        country_filter_lower = country_filter.lower().strip()
        orders_without_country = 0
        
        for order in orders:
            # Extrair pa√≠s (pode ser objeto ou string)
            country_obj = order.get('country', {})
            
            if isinstance(country_obj, dict):
                country_name = country_obj.get('name', '')
            else:
                country_name = str(country_obj)
            
            if not country_name:
                orders_without_country += 1
                continue
            
            # Compara√ß√£o case-insensitive
            if country_name.lower().strip() == country_filter_lower:
                filtered_orders.append(order)
        
        logger.info(f"üåç Resultado do filtro de pa√≠s:")
        logger.info(f"   - Orders do pa√≠s '{country_filter}': {len(filtered_orders)}")
        logger.info(f"   - Orders sem pa√≠s v√°lido: {orders_without_country}")
        logger.info(f"   - Total processados: {len(orders)}")
        
        return filtered_orders
    
    def process_orders_data(self, orders: List[Dict], pais_filtro: Optional[str] = None) -> Dict:
        """
        Processa dados de orders e cria tabela cruzada por Produto x Pa√≠s x Status
        
        Args:
            orders: Lista de orders da API
            pais_filtro: Pa√≠s espec√≠fico para filtrar (opcional)
            
        Returns:
            Dict com dados processados em formato de tabela cruzada
        """
        
        if not orders:
            return {
                'dados_processados': [],
                'estatisticas': {
                    'total_orders': 0,
                    'produtos_unicos': 0,
                    'paises_unicos': 0,
                    'status_unicos': 0
                },
                'status_nao_mapeados': []
            }
        
        # Agrupar dados por Produto + Pa√≠s + Status
        agrupamento = {}
        status_nao_mapeados = set()
        produtos = set()
        paises = set()
        status_encontrados = set()
        
        for order in orders:
            # Extrair nome do produto dos produtos aninhados
            produto = 'Produto Desconhecido'
            if order.get('products') and len(order['products']) > 0:
                produto = order['products'][0].get('name', 'Produto Desconhecido')
            
            # Extrair pa√≠s (√© um objeto, n√£o string)
            pais_obj = order.get('country', {})
            pais = pais_obj.get('name', 'Pa√≠s Desconhecido') if isinstance(pais_obj, dict) else str(pais_obj)
            
            # Status de shipping  
            status_original = order.get('shipping_status', 'Status Desconhecido')
            
            # Aplicar filtro de pa√≠s se especificado
            if pais_filtro and pais.lower() != pais_filtro.lower():
                continue
            
            # Mapear status para portugu√™s
            status = self.status_mapping.get(status_original, status_original)
            if status == status_original and status_original not in self.status_mapping:
                status_nao_mapeados.add(status_original)
            
            produtos.add(produto)
            paises.add(pais)
            status_encontrados.add(status)
            
            # Criar chave √∫nica para agrupamento
            chave = (produto, pais)
            
            if chave not in agrupamento:
                agrupamento[chave] = {
                    'produto': produto,
                    'pais': pais,
                    'total': 0
                }
            
            # Incrementar contador do status
            if status not in agrupamento[chave]:
                agrupamento[chave][status] = 0
            
            agrupamento[chave][status] += 1
            agrupamento[chave]['total'] += 1
        
        # Converter para lista e ordenar
        dados_processados = list(agrupamento.values())
        dados_processados.sort(key=lambda x: (x['produto'], x['pais']))
        
        # Criar linha de TOTAL agregado
        if dados_processados:
            # Coletar todos os status √∫nicos dos dados
            status_unicos = set()
            for item in dados_processados:
                for key in item.keys():
                    if key not in ['produto', 'pais', 'total']:
                        status_unicos.add(key)
            
            # Calcular totais por status
            total_row = {
                'produto': 'TOTAL',
                'pais': 'Todos',
                'total': sum(item['total'] for item in dados_processados)
            }
            
            # Somar todos os status
            for status in status_unicos:
                total_row[status] = sum(item.get(status, 0) for item in dados_processados)
            
            # Adicionar linha TOTAL ao final
            dados_processados.append(total_row)
        
        # Calcular estat√≠sticas
        estatisticas = {
            'total_orders': len(orders),
            'produtos_unicos': len(produtos),
            'paises_unicos': len(paises),
            'status_unicos': len(status_encontrados),
            'orders_processados': sum(item['total'] for item in dados_processados)
        }
        
        logger.info(f"Processamento conclu√≠do: {estatisticas['total_orders']} orders -> {len(dados_processados)} linhas agrupadas")
        
        # DEBUG: Log da estrutura dos dados processados
        logger.info(f"üîç DEBUG: Primeiros 3 items dos dados processados:")
        for i, item in enumerate(dados_processados[:3]):
            logger.info(f"   [{i}] {item}")
        if len(dados_processados) > 3:
            logger.info(f"   ... e mais {len(dados_processados) - 3} items")
        
        # DEBUG: Log da linha TOTAL se existir
        total_row = next((item for item in dados_processados if item.get('produto') == 'TOTAL'), None)
        if total_row:
            logger.info(f"üîç DEBUG: Linha TOTAL encontrada: {total_row}")
        else:
            logger.info(f"üîç DEBUG: Nenhuma linha TOTAL encontrada")
        
        return {
            'dados_processados': dados_processados,
            'estatisticas': estatisticas,
            'status_nao_mapeados': list(status_nao_mapeados),
            'status': 'success'
        }
    
    def test_connection(self) -> Dict:
        """Testa conectividade com API PrimeCOD"""
        try:
            # Testar com um endpoint que sabemos que existe (orders p√°gina 1)
            # Usar m√©todo POST correto
            response = self._make_request('POST', f"{self.base_url}/orders", json={"page": 1})
            data = response.json()
            
            # Extrair informa√ß√µes √∫teis da resposta
            orders_count = len(data.get('data', []))
            total = data.get('total', 0)
            last_page = data.get('last_page', 0)
            per_page = data.get('per_page', 0)
            
            return {
                'status': 'success',
                'message': 'Conex√£o com PrimeCOD estabelecida com sucesso',
                'api_status': response.status_code,
                'token_valido': True,
                'api_info': {
                    'orders_primeira_pagina': orders_count,
                    'total_orders': total,
                    'total_paginas': last_page,
                    'orders_por_pagina': per_page
                }
            }
            
        except PrimeCODAPIError as e:
            # Se for erro de token (401), reportar especificamente
            if "401" in str(e):
                return {
                    'status': 'error',
                    'message': 'Token PrimeCOD inv√°lido ou expirado',
                    'api_status': 401,
                    'token_valido': False
                }
            else:
                return {
                    'status': 'error',
                    'message': f'Erro na API PrimeCOD: {str(e)}',
                    'api_status': None,
                    'token_valido': False
                }
        except Exception as e:
            return {
                'status': 'error',
                'message': f'Erro inesperado ao conectar: {str(e)}',
                'api_status': None,
                'token_valido': False
            }