"""
Background Jobs para coleta ass√≠ncrona PrimeCOD
"""
import logging
import time
from typing import Dict, Optional, List
from django.core.cache import cache
from django.contrib.auth.models import User
from .clients.primecod_client import PrimeCODClient, PrimeCODAPIError
from .models import AnalisePrimeCOD

logger = logging.getLogger(__name__)

def coletar_orders_primecod_async(
    user_id: int,
    data_inicio: str,
    data_fim: str,
    pais_filtro: Optional[str] = None,
    max_paginas: int = 1000,  # ‚ö° ULTRA-OTIMIZADO: Suporte completo a 1000+ p√°ginas
    nome_analise: Optional[str] = None,
    job_id: Optional[str] = None
) -> Dict:
    """
    Job ass√≠ncrono para coletar orders PrimeCOD sem timeout
    
    Args:
        user_id: ID do usu√°rio que solicitou
        data_inicio: Data in√≠cio filtro
        data_fim: Data fim filtro  
        pais_filtro: Pa√≠s para filtrar
        max_paginas: M√°ximo de p√°ginas
        nome_analise: Nome para salvar an√°lise
        job_id: ID do job RQ para tracking
        
    Returns:
        Dict com resultado da coleta
    """
    
    # Cache key para progresso
    progress_key = f"primecod_job_progress_{job_id}" if job_id else None
    
    try:
        # Atualizar progresso inicial
        if progress_key:
            cache.set(progress_key, {
                'status': 'iniciando',
                'progresso': 0,
                'paginas_processadas': 0,
                'orders_coletados': 0,
                'tempo_decorrido': 0,
                'message': 'Inicializando cliente PrimeCOD...'
            }, timeout=1800)  # 30 minutos
        
        logger.info(f"üöÄ Iniciando coleta ass√≠ncrona PrimeCOD para usu√°rio {user_id}")
        
        # Verificar usu√°rio
        try:
            user = User.objects.get(id=user_id)
        except User.DoesNotExist:
            raise Exception(f"Usu√°rio {user_id} n√£o encontrado")
        
        # Inicializar cliente
        client = PrimeCODClient()
        
        # Configurar coleta SEM timeouts agressivos
        date_range = {
            'start': data_inicio,
            'end': data_fim
        }
        
        logger.info(f"üìä Configura√ß√£o da coleta:")
        logger.info(f"   Usu√°rio: {user.username}")
        logger.info(f"   Per√≠odo: {data_inicio} at√© {data_fim}")
        logger.info(f"   Pa√≠s: {pais_filtro or 'Todos'}")
        logger.info(f"   Max p√°ginas: {max_paginas}")
        
        # Callback para atualizar progresso
        def update_progress(pages_processed: int, orders_collected: int, elapsed_time: float, total_pages: Optional[int] = None):
            if progress_key:
                progress_percent = 0
                if total_pages and total_pages > 0:
                    progress_percent = min((pages_processed / min(total_pages, max_paginas)) * 100, 100)
                
                cache.set(progress_key, {
                    'status': 'coletando',
                    'progresso': progress_percent,
                    'paginas_processadas': pages_processed,
                    'orders_coletados': orders_collected,
                    'tempo_decorrido': elapsed_time,
                    'total_paginas': total_pages,
                    'max_paginas': max_paginas,
                    'message': f'Coletando p√°gina {pages_processed}... ({orders_collected} orders coletados)'
                }, timeout=1800)
        
        # Coletar orders com callback de progresso
        start_time = time.time()
        
        # Atualizar m√©todo get_orders para aceitar callback
        resultado = client.get_orders_with_progress(
            page=1,
            date_range=date_range,
            max_pages=max_paginas,
            country_filter=pais_filtro,
            progress_callback=update_progress
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        logger.info(f"‚úÖ Coleta ass√≠ncrona finalizada:")
        logger.info(f"   Dura√ß√£o: {duration:.1f}s ({duration/60:.1f} min)")
        logger.info(f"   Orders coletados: {resultado['total_orders']}")
        logger.info(f"   P√°ginas processadas: {resultado['pages_processed']}")
        
        # Atualizar progresso final
        if progress_key:
            cache.set(progress_key, {
                'status': 'processando',
                'progresso': 95,
                'paginas_processadas': resultado['pages_processed'],
                'orders_coletados': resultado['total_orders'],
                'tempo_decorrido': duration,
                'message': 'Processando dados coletados...'
            }, timeout=1800)
        
        # Processar dados
        orders_processados = client.process_orders_data(
            orders=resultado['orders'],
            pais_filtro=None  # Filtro j√° aplicado
        )
        
        # Salvar an√°lise se nome foi fornecido
        analise_id = None
        if nome_analise:
            try:
                analise = AnalisePrimeCOD.objects.create(
                    nome=nome_analise,
                    tipo='PRIMECOD_API_ASYNC',
                    criado_por=user,
                    dados_processados=orders_processados['dados_processados'],
                    dados_orders=resultado['orders']  # Manter dados originais
                )
                analise_id = analise.id
                logger.info(f"üìÅ An√°lise '{nome_analise}' salva com ID {analise_id}")
            except Exception as e:
                logger.error(f"‚ùå Erro ao salvar an√°lise: {str(e)}")
        
        # Resultado final
        resultado_final = {
            'status': 'success',
            'job_id': job_id,
            'user_id': user_id,
            'duracao': duration,
            'analise_id': analise_id,
            'dados_brutos': {
                'total_orders_raw': resultado.get('total_orders_raw', resultado['total_orders']),
                'total_orders_filtered': resultado['total_orders'],
                'pages_processed': resultado['pages_processed'],
                'date_range_applied': resultado['date_range_applied'],
                'country_filter_applied': resultado.get('country_filter_applied'),
                'data_source': 'async_job'
            },
            'dados_processados': orders_processados['dados_processados'],
            'estatisticas': orders_processados['estatisticas'],
            'status_nao_mapeados': orders_processados['status_nao_mapeados'],
            'message': f"Coleta ass√≠ncrona conclu√≠da em {duration/60:.1f} min: {resultado['total_orders']} orders processados"
        }
        
        # Atualizar progresso final
        if progress_key:
            cache.set(progress_key, {
                'status': 'concluido',
                'progresso': 100,
                'paginas_processadas': resultado['pages_processed'],
                'orders_coletados': resultado['total_orders'],
                'tempo_decorrido': duration,
                'analise_id': analise_id,
                'message': f'Conclu√≠do! {resultado["total_orders"]} orders em {duration/60:.1f} min',
                'resultado': resultado_final
            }, timeout=3600)  # Manter resultado por 1 hora
        
        logger.info(f"üéØ Job ass√≠ncrono finalizado com sucesso para {user.username}")
        return resultado_final
        
    except PrimeCODAPIError as e:
        error_msg = f"Erro na API PrimeCOD: {str(e)}"
        logger.error(error_msg)
        
        if progress_key:
            cache.set(progress_key, {
                'status': 'erro',
                'progresso': 0,
                'message': error_msg,
                'error': str(e)
            }, timeout=3600)
        
        return {
            'status': 'error',
            'job_id': job_id,
            'user_id': user_id,
            'message': error_msg
        }
        
    except Exception as e:
        error_msg = f"Erro inesperado: {str(e)}"
        logger.error(error_msg)
        
        if progress_key:
            cache.set(progress_key, {
                'status': 'erro',
                'progresso': 0,
                'message': error_msg,
                'error': str(e)
            }, timeout=3600)
        
        return {
            'status': 'error',
            'job_id': job_id,
            'user_id': user_id,
            'message': error_msg
        }